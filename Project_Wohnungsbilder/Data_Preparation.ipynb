{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier für Wohnungsbilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image\n",
    "from PIL.ExifTags import TAGS\n",
    "\n",
    "import os, sys\n",
    "from shutil import copyfile\n",
    "\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "# load images\n",
    "all_files = os.listdir(\"data/raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract image title from EXIF\n",
    "def extract_labels(image_files, field_name = \"XPSubject\"):\n",
    "    \n",
    "    # extract field from Exif\n",
    "    def get_field(exif, field):\n",
    "        for (k,v) in exif.items():\n",
    "            if TAGS.get(k) == field:\n",
    "                return v.decode(\"utf-16\")\n",
    "\n",
    "    labels = {}\n",
    "\n",
    "    for i in image_files:\n",
    "        img = PIL.Image.open(\"data/raw/\" + i)\n",
    "        exif = img._getexif()\n",
    "        title = get_field(exif, field_name)\n",
    "        labels[i] = title\n",
    "        img.close()\n",
    "\n",
    "    return labels\n",
    "\n",
    "all_labels = extract_labels(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bad', 'Innenansicht', 'Grundriss', 'Aussenansicht', 'Divers', 'Küche'}\n",
      "6 Classes\n"
     ]
    }
   ],
   "source": [
    "# consolidate labels (e.g. different languages, Special Characters)\n",
    "def consolidate_labels(labels):\n",
    "    \n",
    "    # consolidate languages\n",
    "    recodes_language = {\n",
    "        \"Plan d'ensemble\": \"Grundriss\",\n",
    "        \"Pianta\":\"Grundriss\",\n",
    "        \"Vue extérieure\": \"Aussenansicht\",\n",
    "        \"Cuisine\": \"Küche\",\n",
    "        \"Salle de bains\":\"Bad\",\n",
    "        \"Vue intérieure\":\"Innenansicht\",\n",
    "        \"Cucina\":\"Küche\",\n",
    "        \"Bagno\":\"Bad\",\n",
    "        \"Diverse\":\"Divers\",\n",
    "        \"Varie\": \"Divers\",\n",
    "        \"Bild  LIA\":\"Divers\",\n",
    "        \"immagine  LIA\":\"Divers\",\n",
    "        \"immagine  LIA\":\"Divers\",\n",
    "        \"Balkon/Terrasse/Sitzplatz\":\"Balkon_Terrasse_Sitzplatz\",\n",
    "        \"Balcone/terrazza/posto a sedere\":\"Balkon_Terrasse_Sitzplatz\",\n",
    "        \"Veduta esterna\":\"Aussenansicht\", \n",
    "        \"Stanza\":\"Zimmer\",\n",
    "        \"Vue\":\"Aussicht\",\n",
    "        \"Prospettiva\":\"Aussicht\",\n",
    "        \"Soggiorno\":\"Wohnzimmer\", \n",
    "        \"Séjour\":\"Wohnzimmer\",\n",
    "        \"Pièce\":\"Zimmer\",\n",
    "        \"Veduta interna\":\"Innenansicht\", \n",
    "        \"corridoio\":\"Korridor\",\n",
    "        \"couloir\":\"Korridor\"\n",
    "    }\n",
    "    \n",
    "    # group classes to get approx. even distribution \n",
    "    recodes_groups = {\n",
    "        \"Aussenansicht\":\"Aussenansicht\",\n",
    "        \"Küche\":\"Küche\", \n",
    "        \"Bad\":\"Bad\",\n",
    "        \"Zimmer\":\"Innenansicht\",\n",
    "        \"Innenansicht\":\"Innenansicht\",\n",
    "        \"Wohnzimmer\":\"Innenansicht\",\n",
    "        \"Korridor\":\"Innenansicht\",\n",
    "        \"Grundriss\":\"Grundriss\",\n",
    "        \"Divers\":\"Divers\",\n",
    "        \"Aussicht\":\"Divers\",\n",
    "        \"Balkon_Terrasse_Sitzplatz\":\"Divers\"\n",
    "    }\n",
    "    \n",
    "    for l in labels.keys():\n",
    "        if labels[l] in recodes_language.keys():\n",
    "            labels[l] = recodes_language[labels[l]]\n",
    "        \n",
    "        if labels[l] in recodes_groups.keys():\n",
    "            labels[l] = recodes_groups[labels[l]]\n",
    "            \n",
    "    return(labels)\n",
    "\n",
    "\n",
    "all_labels_clean = consolidate_labels(all_labels)\n",
    "classes = set(all_labels_clean.values())           \n",
    "print(label_set)\n",
    "print(len(classes), \"Classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize files in one folder per class\n",
    "def organize_files(input_dir, output_dir, labels, files):\n",
    "    \n",
    "    classes = set(labels.values())\n",
    "\n",
    "    for c in classes:\n",
    "        if not os.path.isdir(output_dir+c):\n",
    "            os.mkdir(output_dir+c)\n",
    "    \n",
    "    for f in files:\n",
    "        src = input_dir + f        \n",
    "        dst = output_dir + labels[f] + \"/\" + f\n",
    "        os.rename(src, dst)\n",
    "        \n",
    "\n",
    "# Split training, validation and testset\n",
    "def split_data(input_dir, output_dir, labels_clean, probs=(0.75, 0.125, 0.125)):\n",
    "    \n",
    "    train_dir = output_dir + \"train/\"\n",
    "    valid_dir = output_dir + \"valid/\"\n",
    "    test_dir  = output_dir + \"test/\"\n",
    "    \n",
    "    # setup folders\n",
    "    if not os.path.isdir(train_dir): os.mkdir(train_dir)\n",
    "    if not os.path.isdir(valid_dir): os.mkdir(valid_dir)\n",
    "    if not os.path.isdir(test_dir): os.mkdir(test_dir)\n",
    "\n",
    "    # split data\n",
    "    np.random.seed(1)\n",
    "    splits = np.random.choice([0,1,2], size = len(labels), p = probs)\n",
    "    labels_keys = np.array(list(labels_clean.keys()))\n",
    "    \n",
    "    train_files = labels_keys[splits == 0]\n",
    "    valid_files = labels_keys[splits == 1]\n",
    "    test_files  = labels_keys[splits == 2]\n",
    "    \n",
    "    # copy files to correct train-, valid-, test-folder\n",
    "    for f in train_files: copyfile(input_dir + f, train_dir + f)\n",
    "    for f in valid_files: copyfile(input_dir + f, valid_dir + f)\n",
    "    for f in test_files: copyfile(input_dir + f, test_dir + f)\n",
    "        \n",
    "    # organize files by class\n",
    "    organize_files(train_dir, train_dir, labels_clean, train_files)\n",
    "    organize_files(valid_dir, valid_dir, labels_clean, valid_files)\n",
    "    organize_files(test_dir, test_dir, labels_clean, test_files)\n",
    "    \n",
    "split_data(\"data/raw/\", \"data/clean/\", labels_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_to_array(data_dir, img_width, img_height):\n",
    "    \n",
    "    import os\n",
    "    import numpy as np\n",
    "    from imageio import imread\n",
    "    from skimage.transform import resize\n",
    "    \n",
    "    classes = os.listdir(data_dir)\n",
    "    \n",
    "    # list all files\n",
    "    all_files = []\n",
    "    for root, directories, filenames in os.walk(data_dir):        \n",
    "        for filename in filenames:\n",
    "            all_files.append(os.path.join(root,filename))\n",
    "\n",
    "    X = np.zeros((len(all_files), img_width, img_height, 3))\n",
    "    ind = 0\n",
    "    for f in all_files:\n",
    "        img = imread(f)\n",
    "        img_resized = resize(img, [img_width, img_height])\n",
    "        X[ind,:,:,:] = img_resized\n",
    "        ind += 1\n",
    "        \n",
    "    Y = list()\n",
    "    for c in classes:\n",
    "        cdir = data_dir+c+\"/\"\n",
    "        cfiles = os.listdir(cdir)\n",
    "        \n",
    "        Y += [c]*len(cfiles)\n",
    "        \n",
    "    return X, np.array(Y)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programme\\anaconda35\\envs\\d1_course\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1465, 224, 224, 3)\n",
      "(1465,)\n",
      "(264, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = images_to_array(\"data/clean/train/\", 224, 224)\n",
    "X_valid, Y_valid = images_to_array(\"data/clean/valid/\", 224, 224)\n",
    "X_test, Y_test = images_to_array(\"data/clean/test/\", 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToOneHot(Y):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    \n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(Y)\n",
    "    \n",
    "    # binary encode\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "    \n",
    "    return onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=convertToOneHot(Y_train)\n",
    "Y_valid=convertToOneHot(Y_valid)\n",
    "Y_test=convertToOneHot(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1465, 224, 224, 3)\n",
      "(1465, 6)\n",
      "(264, 224, 224, 3)\n",
      "(264, 6)\n",
      "(271, 224, 224, 3)\n",
      "(271, 6)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(Y_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_hdf5(datasets, output_path):\n",
    "    \n",
    "    import h5py\n",
    "    \n",
    "    h5f = h5py.File(output_path, 'w')\n",
    "    for d in datasets.keys():\n",
    "        h5f.create_dataset(d, data=datasets[d])\n",
    "    \n",
    "    h5f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\"X_train\":X_train,\n",
    "            \"Y_train\":Y_train,\n",
    "            \"X_valid\":X_valid,\n",
    "            \"Y_valid\":Y_valid,\n",
    "            \"X_test\":X_test,\n",
    "            \"Y_test\":Y_test }\n",
    "\n",
    "save_to_hdf5(datasets, \"data/wohnungsbilder2000_tvt.hdf5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
